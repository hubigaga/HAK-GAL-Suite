# api.py
# Phase 24.3: Full Response API with Timeout Protection
# - F√§ngt die Ausgaben von `ask` und `explain` ab und sendet sie an das Frontend.
# - Verhindert Timeouts durch Command-Limits

from flask import Flask, request, jsonify
from flask_cors import CORS
import traceback
import io
import sys
import signal
import threading
from contextlib import contextmanager

# Import der neuen modularen Struktur
from backend.services import KAssistant

# --- Timeout-Management ---
class TimeoutException(Exception):
    pass



# --- Initialisierung ---
app = Flask(__name__)
origins = [
    "http://localhost:3000", "http://localhost:8080", "http://localhost:8081", "http://localhost:5173",
    "http://127.0.0.1:3000", "http://127.0.0.1:8080", "http://127.0.0.1:8081", "http://127.0.0.1:5173"
]
CORS(app, resources={
    r"/api/*": {
        "origins": origins,
        "methods": ["GET", "POST", "OPTIONS"],
        "allow_headers": ["Content-Type", "Authorization"],
        "supports_credentials": True
    }
})

print("ü§ñ Initialisiere K-Assistant... Bitte warten.")
assistant = KAssistant()
print("‚úÖ K-Assistant ist bereit.")

# BACKEND-REPARATUR: Best√§tige implementierte Fixes
print("üîß Backend-Reparaturen aktiv:")
print("   ‚úÖ advanced_tools_status Command implementiert")
print("   ‚úÖ enable_advanced_features Command implementiert")
print("   ‚úÖ Performance-Metriken-Collection aktiviert")
print("   ‚úÖ hybrid_all Strategy Timeout-Protection aktiv")

# --- Hilfsfunktionen ---
def get_performance_metrics():
    """Sammelt strukturierte Performance-Metriken f√ºr das Frontend"""
    try:
        # Portfolio-Performance Metriken
        portfolio_stats = assistant.core.get_portfolio_stats()
        
        # Cache-Metriken
        proof_cache = assistant.core.proof_cache
        prompt_cache = assistant.ensemble_manager.prompt_cache
        
        # Advanced Tools Metriken
        advanced_metrics = {}
        if hasattr(assistant, 'advanced_relevance_manager') and assistant.advanced_relevance_manager:
            advanced_stats = assistant.advanced_relevance_manager.get_stats()
            advanced_metrics = {
                "orchestrator_available": advanced_stats.get('orchestrator_available', False),
                "total_facts": advanced_stats.get('total_facts', 0),
                "available_filters": advanced_stats.get('available_filters', []),
                "strategy_usage": advanced_stats.get('strategy_usage', {}),
                "cache_hit_rate": advanced_stats.get('cache_hit_rate', 0.0),
                "avg_query_time": advanced_stats.get('avg_query_time', 0.0)
            }
        
        return {
            "portfolio_performance": {
                "prover_stats": portfolio_stats.get('performance', {}),
                "usage_counts": portfolio_stats.get('usage_count', {}),
                "total_queries": sum(portfolio_stats.get('usage_count', {}).values())
            },
            "cache_metrics": {
                "proof_cache": {
                    "size": proof_cache.size,
                    "hit_rate": proof_cache.hit_rate,
                    "total_hits": proof_cache.hits,
                    "total_misses": proof_cache.misses
                },
                "prompt_cache": {
                    "size": prompt_cache.size,
                    "hit_rate": prompt_cache.hit_rate,
                    "total_hits": prompt_cache.hits,
                    "total_misses": prompt_cache.misses
                }
            },
            "advanced_tools_metrics": advanced_metrics,
            "system_metrics": {
                "total_facts": len(assistant.core.K),
                "potential_facts": len(assistant.potential_new_facts),
                "parser_success_rate": (assistant.core.parser_stats["success"] / 
                                       max(assistant.core.parser_stats["total"], 1)) * 100,
                "rag_enabled": assistant.wissensbasis_manager.get_statistics()['enabled'],
                "rag_chunks": assistant.wissensbasis_manager.get_statistics()['chunk_count']
            }
        }
    except Exception as e:
        logger.error(f"Fehler beim Sammeln der Performance-Metriken: {e}")
        return {}

def get_current_state():
    # Verbesserte RAG-Kontext-Formatierung
    rag_context = "üìä RAG SYSTEM STATUS\n" + "="*40 + "\n"
    
    if hasattr(assistant, 'wissensbasis_manager') and assistant.wissensbasis_manager.chunks:
        doc_count = len(assistant.wissensbasis_manager.doc_paths)
        chunk_count = len(assistant.wissensbasis_manager.chunks)
        
        rag_context += f"üìÅ Indizierte Dokumente: {doc_count}\n"
        rag_context += f"üß© Text-Chunks: {chunk_count}\n\n"
        
        # Zeige Dokumentenliste
        if assistant.wissensbasis_manager.doc_paths:
            rag_context += "üìö DOKUMENT-QUELLEN:\n"
            for doc_id, path in assistant.wissensbasis_manager.doc_paths.items():
                rag_context += f"  ‚Ä¢ {doc_id}\n"
            rag_context += "\n"
        
        # Zeige Sample-Chunks formatiert
        rag_context += "üîç CONTENT-PREVIEW (Top 3):\n"
        for i, chunk_info in enumerate(assistant.wissensbasis_manager.chunks[:3]):
            source = chunk_info.get('source', 'Unknown')
            text = chunk_info.get('text', '').strip()[:150]
            # Besser lesbare Formatierung
            rag_context += f"\n[Chunk {i+1} ‚Ä¢ {source}]\n"
            rag_context += f"{text}...\n"
            rag_context += "-" * 40 + "\n"
        
        if len(assistant.wissensbasis_manager.chunks) > 5:
            remaining = len(assistant.wissensbasis_manager.chunks) - 5
            rag_context += f"    ... und {remaining} weitere Chunks\n"
            
        # Bindestrich-Hinweis
        rag_context += "\nüéØ BINDESTRICH-SUPPORT AKTIV\n"
        rag_context += "    Teste: RAG-Pipeline, AI-System, Machine-Learning\n"
    else:
        rag_context += "‚ùå Noch keine Dokumente indiziert\n"
        rag_context += "üí° Verwende 'build_kb <pfad>' zum Laden von Dokumenten\n\n"
        rag_context += "üß™ QUICK TESTS:\n"
        rag_context += "    parse Funktioniert(RAG-Pipeline).\n"
        rag_context += "    add_raw IstAktiv(AI-System).\n"
        rag_context += "    ask Ist das System kritisch?\n"
    
    # DEBUG: Zeige aktuelle State-Werte
    permanent_knowledge = getattr(assistant.core, 'K', [])
    learning_suggestions = getattr(assistant, 'potential_new_facts', [])
    data_sources = list(assistant.wissensbasis_manager.doc_paths.keys()) if hasattr(assistant, 'wissensbasis_manager') else []
    llm_status = get_llm_status()  # NEUE LLM-Status-Info
    
    print(f"üîç Backend State Debug:")
    print(f"   - permanentKnowledge: {len(permanent_knowledge)} items")
    print(f"   - learningSuggestions: {len(learning_suggestions)} items")
    print(f"   - dataSources: {len(data_sources)} items")
    print(f"   - ragContext length: {len(rag_context)} chars")
    print(f"   - LLM Status: {llm_status['llm_active']}/{llm_status['llm_count']} active")
    
    if learning_suggestions:
        print(f"   - Learning Suggestions Details:")
        for i, suggestion in enumerate(learning_suggestions[:3]):
            print(f"     [{i}] {suggestion}")
    
    # ENHANCED: F√ºge Performance-Metriken hinzu
    performance_metrics = get_performance_metrics()
    
    return {
        "permanentKnowledge": permanent_knowledge,
        "learningSuggestions": learning_suggestions,
        "ragContext": rag_context,
        "dataSources": data_sources,
        "llmStatus": llm_status,  # NEUE LLM-Status-Info f√ºr Frontend
        "performanceMetrics": performance_metrics  # NEUE Performance-Metriken
    }

def capture_output_with_timeout(func, timeout_seconds, *args, **kwargs):
    """F√§ngt die print-Ausgaben einer Funktion ab und gibt sie als String zur√ºck - mit Timeout."""
    result = {"output": None, "error": None}
    
    def target():
        try:
            old_stdout = sys.stdout
            sys.stdout = captured_output = io.StringIO()
            
            func(*args, **kwargs)
            
            sys.stdout = old_stdout
            result["output"] = captured_output.getvalue()
        except Exception as e:
            result["error"] = str(e)
    
    thread = threading.Thread(target=target)
    thread.start()
    thread.join(timeout_seconds)
    
    if thread.is_alive():
        # Thread ist noch am Laufen - Timeout!
        print(f"‚è±Ô∏è TIMEOUT: Command nach {timeout_seconds}s abgebrochen")
        result["error"] = f"Command-Timeout nach {timeout_seconds} Sekunden"
        # Note: Thread l√§uft weiter, aber wir ignorieren das Ergebnis
    
    return result["output"], result["error"]

def get_llm_status():
    """Gibt LLM-Status f√ºr Header zur√ºck"""
    try:
        provider_info = []
        if hasattr(assistant, 'ensemble_manager') and assistant.ensemble_manager.providers:
            for p in assistant.ensemble_manager.providers:
                provider_name = p.__class__.__name__.replace("Provider", "")
                try:
                    # Schneller Test ohne echte API-Abfrage
                    provider_info.append({
                        "name": provider_name,
                        "status": "‚úÖ Ready"
                    })
                except:
                    provider_info.append({
                        "name": provider_name, 
                        "status": "‚ùå Error"
                    })
        
        return {
            "llm_count": len(provider_info),
            "llm_active": len([p for p in provider_info if "‚úÖ" in p["status"]]),
            "llm_providers": provider_info
        }
    except Exception as e:
        return {
            "llm_count": 0,
            "llm_active": 0, 
            "llm_providers": [],
            "error": str(e)
        }

# --- Debug-Endpunkt ---
@app.route('/api/test', methods=['GET'])
def test_connection():
    return jsonify({
        "status": "Backend l√§uft!",
        "cors_origins": origins,
        "backend_ready": True
    })

# --- API-Endpunkt ---
@app.route('/api/command', methods=['POST', 'OPTIONS'])
def handle_command():
    # CORS Preflight Request
    if request.method == 'OPTIONS':
        return '', 200
    
    # Request-Logging f√ºr Debugging
    print(f"üîç Request von: {request.origin}")
    print(f"üîç Headers: {dict(request.headers)}")
    
    data = request.get_json()
    if not data or 'command' not in data:
        return jsonify({"error": "Ung√ºltige Anfrage: 'command' fehlt."}), 400

    full_command = data['command'].strip()
    parts = full_command.split(" ", 1)
    command = parts[0].lower()
    args = parts[1] if len(parts) > 1 else ""
    
    print(f"üì® Command empfangen: '{command}' mit Args: '{args}'")

    try:
        response_data = {}
        chat_response = None
        
        # Verschiedene Timeouts je nach Command-Typ
        timeout_seconds = 30  # Default
        if command in ["ask", "explain"]:
            timeout_seconds = 45  # L√§nger f√ºr komplexe RAG-Queries
        elif command in ["build_kb"]:
            timeout_seconds = 60  # Noch l√§nger f√ºr Dokumenten-Indizierung
        elif command == "learn":
            timeout_seconds = 15  # K√ºrzer f√ºr optimierte Learn-Funktion

        print(f"‚è±Ô∏è Command-Timeout: {timeout_seconds}s")

        if command in ["add_raw", "retract", "learn", "build_kb", "clearcache"]:
            # Befehle, die den Zustand √§ndern UND Ausgaben haben
            print(f"üîß Verarbeite State-Change Command: {command}")
            if command == "add_raw": 
                chat_response, error = capture_output_with_timeout(assistant.add_raw, timeout_seconds, args)
                if error: raise Exception(error)
                # Auto-save nach √Ñnderungen
                assistant.save_kb(assistant.kb_filepath)
                print("üíæ Knowledge Base automatisch gespeichert")
            elif command == "retract": 
                chat_response, error = capture_output_with_timeout(assistant.retract, timeout_seconds, args)
                if error: raise Exception(error)
                assistant.save_kb(assistant.kb_filepath)
                print("üíæ Knowledge Base automatisch gespeichert")
            elif command == "learn": 
                chat_response, error = capture_output_with_timeout(assistant.learn_facts, timeout_seconds)
                if error: raise Exception(error)
                # Auto-save nach Learn
                assistant.save_kb(assistant.kb_filepath)
                print("üíæ Knowledge Base automatisch gespeichert")
            elif command == "build_kb": 
                chat_response, error = capture_output_with_timeout(assistant.build_kb_from_file, timeout_seconds, args)
                if error: raise Exception(error)
            elif command == "clearcache": 
                chat_response, error = capture_output_with_timeout(assistant.clear_cache, timeout_seconds)
                if error: raise Exception(error)
        
        elif command in ["ask", "explain", "what_is", "show", "status", "search", "sources", "parse", "help", "wolfram_stats", "add_oracle", "advanced_tools_status", "enable_advanced_features"]:
             # Befehle, die eine Text-Antwort erzeugen
            if command == "ask": 
                chat_response, error = capture_output_with_timeout(assistant.ask, timeout_seconds, args)
                if error: raise Exception(error)
            elif command == "explain": 
                chat_response, error = capture_output_with_timeout(assistant.explain, timeout_seconds, args)
                if error: raise Exception(error)
            elif command == "what_is": 
                chat_response, error = capture_output_with_timeout(assistant.what_is, timeout_seconds, args)
                if error: raise Exception(error)
            elif command == "show": 
                # SPEZIAL: show() gibt Dict zur√ºck, muss formatiert werden
                try:
                    data = assistant.show()
                    chat_response = "\n=== WISSENSBASIS √úBERBLICK ===\n"
                    chat_response += f"üìä Permanente Fakten: {len(data['permanent_knowledge'])}\n"
                    chat_response += f"üí° Lernbare Fakten: {len(data['learnable_facts'])}\n"
                    chat_response += f"üìö RAG Dokumente: {data['rag_stats']['doc_count']}\n"
                    chat_response += f"üß© RAG Chunks: {data['rag_stats']['chunk_count']}\n\n"
                    
                    if data['permanent_knowledge']:
                        chat_response += "üîπ PERMANENTE WISSENSBASIS:\n"
                        for i, fact in enumerate(data['permanent_knowledge'][:5], 1):
                            chat_response += f"  [{i}] {fact}\n"
                        if len(data['permanent_knowledge']) > 5:
                            remaining = len(data['permanent_knowledge']) - 5
                            chat_response += f"  ... und {remaining} weitere Fakten\n"
                    
                    if data['learnable_facts']:
                        chat_response += "\nüí° LERNBARE FAKTEN:\n"
                        for i, fact in enumerate(data['learnable_facts'][:3], 1):
                            chat_response += f"  [{i}] {fact}\n"
                        if len(data['learnable_facts']) > 3:
                            remaining = len(data['learnable_facts']) - 3
                            chat_response += f"  ... und {remaining} weitere Fakten\n"
                        chat_response += "\n‚û°Ô∏è Verwende 'learn' um sie zu √ºbernehmen\n"
                except Exception as e:
                    chat_response = f"‚ùå Fehler beim Laden der Wissensbasis: {e}"
            elif command == "status": 
                chat_response, error = capture_output_with_timeout(assistant.status, timeout_seconds)
                if error: raise Exception(error)
            elif command == "search":
                chat_response, error = capture_output_with_timeout(assistant.search, timeout_seconds, args)
                if error: raise Exception(error)
            elif command == "sources":
                chat_response, error = capture_output_with_timeout(assistant.sources, timeout_seconds)
                if error: raise Exception(error)
            elif command == "parse":
                chat_response, error = capture_output_with_timeout(assistant.test_parser, timeout_seconds, args)
                if error: raise Exception(error)
            elif command == "wolfram_stats":
                chat_response, error = capture_output_with_timeout(assistant.wolfram_stats, timeout_seconds)
                if error: raise Exception(error)
            elif command == "add_oracle":
                chat_response, error = capture_output_with_timeout(assistant.add_oracle_predicate, timeout_seconds, args)
                if error: raise Exception(error)
            elif command == "advanced_tools_status":
                chat_response, error = capture_output_with_timeout(assistant.advanced_tools_status, timeout_seconds)
                if error: raise Exception(error)
            elif command == "enable_advanced_features":
                # Special handling for enable_advanced_features - returns boolean
                try:
                    success = assistant.enable_advanced_features()
                    chat_response = f"‚úÖ Erweiterte Features {'erfolgreich aktiviert' if success else 'konnten nicht vollst√§ndig aktiviert werden'}"
                except Exception as e:
                    chat_response = f"‚ùå Fehler beim Aktivieren erweiterter Features: {e}"
            elif command == "help":
                # Direkte Hilfe ohne timeout
                chat_response = """
‚úÖ VERF√úGBARE COMMANDS:

üìã WISSENSBASIS:
  add_raw <formel>   - F√ºgt KERNREGEL hinzu
  retract <formel>   - Entfernt KERNREGEL  
  learn              - Speichert gefundene Fakten
  show               - Zeigt Wissensbasis an
  
üß† RAG & DOKUMENTE:
  build_kb <pfad>    - Indiziert Dokument f√ºr RAG
  search <anfrage>   - Findet Text in der KB
  sources            - Zeigt Wissensquellen an
  
ü§ñ ANFRAGEN:
  ask <frage>        - Beantwortet Frage (mit RAG + Wolfram)
  explain <frage>    - Erkl√§rt eine Antwort
  what_is <entity>   - Zeigt Profil einer Entit√§t
  
üîç WOLFRAM|ALPHA:
  wolfram_stats      - Zeigt Wolfram Cache-Statistiken
  add_oracle <pred>  - F√ºgt Oracle-Pr√§dikat hinzu
  
üöÄ ADVANCED TOOLS:
  advanced_tools_status     - Zeigt Advanced Tools Status
  enable_advanced_features  - Aktiviert erweiterte Features
  
üîß TOOLS:
  parse <formel>     - Testet Parser mit Formel  
  status             - Zeigt Systemstatus
  clearcache         - Leert alle Caches
  
üéØ BINDESTRICH-SUPPORT:
  parse Funktioniert(RAG-Pipeline).
  ask L√§uft das AI-System?
  
üéõÔ∏è STRATEGY-PARAMETER:
  ask --strategy=structural_only <frage>
  ask --strategy=semantic_only <frage>
  ask --strategy=adaptive <frage>
  ask --strategy=hybrid_all <frage>
                """
        
        else:
            # VALIDIERE: Alle Backend-Commands sind verf√ºgbar
            available_commands = ["add_raw", "retract", "learn", "build_kb", "clearcache", 
                                "ask", "explain", "what_is", "show", "status", 
                                "search", "sources", "parse", "help", "wolfram_stats", "add_oracle",
                                "advanced_tools_status", "enable_advanced_features"]
            chat_response = f"‚ùå Unbekannter Befehl: '{command}'\n\n‚úÖ Verf√ºgbare Commands:\n" + "\n".join([f"  ‚Ä¢ {cmd}" for cmd in sorted(available_commands)])

        # Immer den aktuellen Zustand abrufen
        state = get_current_state()
        state["status"] = "success"
        state["lastCommand"] = command
        
        # F√ºge die abgefangene Chat-Antwort hinzu, falls vorhanden
        if chat_response:
            state["chatResponse"] = chat_response
        
        print(f"‚úÖ Command '{command}' erfolgreich verarbeitet in < {timeout_seconds}s")
        return jsonify(state)

    except Exception as e:
        error_msg = str(e)
        print(f"‚ùå Command-Fehler: {error_msg}")
        traceback.print_exc()
        
        # Versuche trotzdem State zu holen f√ºr Frontend
        try:
            state = get_current_state()
            state["status"] = "error"
            state["error"] = error_msg
            state["chatResponse"] = f"üö® Fehler: {error_msg}"
            return jsonify(state), 500
        except:
            return jsonify({"error": error_msg, "status": "error"}), 500

# --- Server starten ---
if __name__ == '__main__':
    print("üöÄ Starte HAK-GAL API Server mit Timeout-Protection...")
    app.run(debug=True, port=5001)